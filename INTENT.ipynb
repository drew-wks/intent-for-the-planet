{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install langchain_community\n",
    "#%pip install ipython\n",
    "#%pip install python-dotenv\n",
    "#%pip install Markdown\n",
    "#%pip install display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "# openai.api_key = st.secrets[\"OPENAI_API_KEY\"] # Use this version for streamlit\n",
    "\n",
    "\n",
    "# Jupyter Notebook version: Specify the path to the parent directory of your project\n",
    "# parent_dir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "# sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_data/response_drew.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def query(question):\n",
    "    user_message = f\"\"\"{question}```{data}```\"\"\"\n",
    "    system_message = \"You are a helpful assistant. Try to answer the users question based on the info in the json provided\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",  # gpt-4\n",
    "        max_tokens=8000,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query(\"does anyone talk about youtube? if so, how?\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility: combine json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def combine_json_files(folder_path, output_file):\n",
    "    combined_data = []\n",
    "\n",
    "    # Iterate over all files in the given folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Open and read the JSON file\n",
    "            with open(file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "                combined_data.append(data)\n",
    "\n",
    "    # Write the combined data to the output file\n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump(combined_data, file, indent=4)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Replace with the path to your folder\n",
    "folder_path = '/Users/drew_wilkins/Drews_Files/Drew/Python/VSCode/INTENT'\n",
    "output_file = 'reponses.json'  # Name of the output file\n",
    "combine_json_files(folder_path, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility: create unique IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "for i in range(1, 21):\n",
    "    id = uuid.uuid4()\n",
    "    print(f\"\"\"            \"p_id\": : \"{id}\",\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data models for INTENT from github\n",
    "Be sure to first push any changes you've made locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import List, Dict, Tuple, Union, Optional\n",
    "from pydantic import BaseModel, Field, field_validator, constr\n",
    "import uuid\n",
    "\n",
    "script_url = \"https://raw.githubusercontent.com/drew-wks/intent-for-the-planet/main/data_models.py\"\n",
    "\n",
    "response = requests.get(script_url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Execute the fetched script\n",
    "    exec(response.text)\n",
    "else:\n",
    "    print(\"Failed to retrieve the script\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a response object by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_example1 = Responses(\n",
    "    my_world=[\"A place of unity and respect\"],\n",
    "    my_planet=[\"A shared home for all beings\"],\n",
    "    care_physical=[\"Regular exercise\", \"Healthy eating\"],\n",
    "    care_mental=[\"Meditation\", \"Reading\"],\n",
    "    my_activities=[\"Public speaking\", \"Writing\"],\n",
    "    my_resources=[\"Books\", \"Community support\"],\n",
    "    care_who=[\"Family\", \"Nation\"],\n",
    "    how_cherish=[\"Promoting sustainability\", \"Educating others\"],\n",
    "    do_more=[\"Listening to diverse perspectives\",\n",
    "             \"Engaging in community service\"],\n",
    "    do_less=[\"Spending time on trivial matters\", \"Neglecting self-care\"],\n",
    "    my_intent=[\"To foster a world of equality and understanding\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_example2 = Responses(\n",
    "    my_world=[\"Respect my authoritah!\"],\n",
    "    my_planet=[\"This big video game\"],\n",
    "    care_physical=[\"Eating Cheesy Poofs and sitting on the couch.\"],\n",
    "    care_mental=[\n",
    "        \"That's the dumbest question I've ever heard. Don't make me smack some sense into you\"],\n",
    "    my_activities=[\n",
    "        \"Coming up with genius plans, playing video games, and bossing people around.\"],\n",
    "    my_resources=[\n",
    "        \"My fortress-like mind. I can lie without blinking. My mom's credit card.\"],\n",
    "    care_who=[\"Me, myself, and I. And my mom. And my kitty sometimes.\"],\n",
    "    how_cherish=[\n",
    "        \"By making sure it serves my interests first. Helping Butters and sometimes Kenny, 'cause he's poor and it's funny. \"],\n",
    "    do_more=[\"Eating junk food, watching more TV, and getting even with Kyle.\"],\n",
    "    do_less=[\n",
    "        \"Listening to Kyle's preachy speeches, doing homework. Less sharing. That's for losers.\"],\n",
    "    my_intent=[\"As Kenny, my Intent is to rule the world, or at least South Park.\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_example3 = Responses(\n",
    "    my_world=[\"A perfectly ordered universe where everyone appreciates the beauty of quantum physics and understands the importance of adhering to a meticulously structured schedule. And where my spot on the couch is forever reserved.\"],\n",
    "    my_planet=[\"A utopia governed by the laws of physics and logic, where discussions on the intricacies of string theory and Star Trek are commonplace.\"],\n",
    "    care_physical=[\"Physical health is of utmost importance, not for vanity, but for the efficient functioning of the brain. That's why I adhere to a strict regimen of stretching and weekly laundry to ensure my Flash T-shirts are bacteria-free.\"],\n",
    "    care_mental=[\"Mental health is paramount. I engage in regular mental exercises, including but not limited to, three-dimensional chess and memorizing the periodic table in reverse. It keeps my cognitive faculties sharp.\"],\n",
    "    my_activities=[\"Conducting groundbreaking physics research, attending comic book conventions in meticulously crafted costumes, and engaging in the occasional 'Bazinga!' to keep my social experiments interesting.\"],\n",
    "    my_resources=[\"My intellect, an extensive collection of comic books and memorabilia, and access to a world-class university laboratory. Also, a roommate agreement that ensures domestic harmony.\"],\n",
    "    care_who=[\"My close-knit group of friends, despite their frequent disregard for the roommate agreement, and my beloved Amy Farrah Fowler. Oh, and my mother, who insists on calling me 'Shelly.'\"],\n",
    "    how_cherish=[\"By maintaining a clean and orderly living environment, ensuring the safety of my collectibles, and dedicating time to my relationships, within scientifically acceptable parameters.\"],\n",
    "    do_more=[\"Expand my research, increase my collection of rare comic books, and perhaps engage in more social activities, as long as they don't interfere with my research or 'Doctor Who' viewing schedule.\"],\n",
    "    do_less=[\"Waste time on frivolous activities that don't stimulate the intellect, like attending mundane social gatherings or engaging in conversations about feelings.\"],\n",
    "    my_intent=[\"As Sheldon Cooper,my Intent is to win the Nobel Prize in Physics, thereby securing my place in scientific history, and to ensure the propagation of knowledge and logic in a world sorely in need of both.\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1. What is your world?': 'A place of unity and respect', \"2. What is 'the planet' is for you?\": 'A shared home for all beings', '3. How do you care for your physical well-being?': 'Regular exercise<br>Healthy eating', '4. How do you care for your mental well-being?': 'Meditation<br>Reading', '5. What are your activities?': 'Public speaking<br>Writing', '6. What are your resources?': 'Books<br>Community support', '7. Who do you care about?': 'Family<br>Nation', '8. How do you cherish the planet?': 'Promoting sustainability<br>Educating others', '9. What do you need to do more of?': 'Listening to diverse perspectives<br>Engaging in community service', '10. What do you need to do less of?': 'Spending time on trivial matters<br>Neglecting self-care', 'My Intent For the Planet': 'To foster a world of equality and understanding'}\n"
     ]
    }
   ],
   "source": [
    "print(response_example1.responses())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save response to a csv file (do not use for a session object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'intent_data_repo/responses.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m             writer\u001b[38;5;241m.\u001b[39mwriterow(headers)\n\u001b[1;32m     17\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwriterow(data\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m---> 20\u001b[0m \u001b[43msave_to_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_example1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mintent_data_repo/responses.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m, in \u001b[0;36msave_to_csv\u001b[0;34m(object, filename)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_to_csv\u001b[39m(\u001b[38;5;28mobject\u001b[39m, filename):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Check if file exists to determine if headers should be written\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     file_exists \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(filename)\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      9\u001b[0m         writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(file)\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# Convert the response to a dictionary using model_dump\u001b[39;00m\n",
      "File \u001b[0;32m~/Drews_Files/Drew/Python/intent-for-the-planet/.venv-311/lib/python3.11/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'intent_data_repo/responses.csv'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "def save_to_csv(object, filename):\n",
    "    # Check if file exists to determine if headers should be written\n",
    "    file_exists = os.path.isfile(filename)\n",
    "\n",
    "    with open(filename, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Convert the response to a dictionary using model_dump\n",
    "        data = object.model_dump()\n",
    "\n",
    "        if not file_exists:\n",
    "            headers = list(data.keys())\n",
    "            writer.writerow(headers)\n",
    "        writer.writerow(data.values())\n",
    "\n",
    "\n",
    "save_to_csv(\n",
    "    response_example1, filename=\"intent_data_repo/responses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_csv(\n",
    "    session_example1, filename=\"intent_data_repo/sessions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's have some fun with Sessions which contain response objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_example1 = Session(\n",
    "    facilitator=4,\n",
    "    language='en',\n",
    "    responses=response_example1\n",
    ")\n",
    "\n",
    "session_example2 = Session(\n",
    "    facilitator=4,\n",
    "    language='en',\n",
    "    responses=response_example2\n",
    ")\n",
    "\n",
    "session_example3 = Session(\n",
    "    facilitator=4,\n",
    "    language='en',\n",
    "    responses=response_example3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Session(session_date=datetime.datetime(2024, 2, 6, 14, 41, 25, 778225), facilitator=4, responses=Responses(responses_id=UUID('73872fd5-d351-4dee-a472-c8eb07eb59d1'), type='ind', my_world=['A place of unity and respect'], my_planet=['A shared home for all beings'], care_physical=['Regular exercise', 'Healthy eating'], care_mental=['Meditation', 'Reading'], my_activities=['Public speaking', 'Writing'], my_resources=['Books', 'Community support'], care_who=['Family', 'Nation'], how_cherish=['Promoting sustainability', 'Educating others'], do_more=['Listening to diverse perspectives', 'Engaging in community service'], do_less=['Spending time on trivial matters', 'Neglecting self-care'], my_intent=['To foster a world of equality and understanding']), language='en', id=UUID('51177fa3-e9a3-4655-8c21-2708f4e7849c'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Session.model_validate(session_example1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__class_vars__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_pydantic_core_schema__',\n",
       " '__get_pydantic_json_schema__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__pydantic_complete__',\n",
       " '__pydantic_core_schema__',\n",
       " '__pydantic_custom_init__',\n",
       " '__pydantic_decorators__',\n",
       " '__pydantic_extra__',\n",
       " '__pydantic_fields_set__',\n",
       " '__pydantic_generic_metadata__',\n",
       " '__pydantic_init_subclass__',\n",
       " '__pydantic_parent_namespace__',\n",
       " '__pydantic_post_init__',\n",
       " '__pydantic_private__',\n",
       " '__pydantic_root_model__',\n",
       " '__pydantic_serializer__',\n",
       " '__pydantic_validator__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_calculate_keys',\n",
       " '_check_frozen',\n",
       " '_copy_and_set_values',\n",
       " '_get_value',\n",
       " '_iter',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'facilitator',\n",
       " 'from_orm',\n",
       " 'id',\n",
       " 'json',\n",
       " 'language',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_construct',\n",
       " 'model_copy',\n",
       " 'model_dump',\n",
       " 'model_dump_json',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'model_json_schema',\n",
       " 'model_parametrized_name',\n",
       " 'model_post_init',\n",
       " 'model_rebuild',\n",
       " 'model_validate',\n",
       " 'model_validate_json',\n",
       " 'model_validate_strings',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'responses',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'session_date',\n",
       " 'update_forward_refs',\n",
       " 'validate']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(session_example1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1. What is your world?': 'A place of unity and respect', \"2. What is 'the planet' is for you?\": 'A shared home for all beings', '3. How do you care for your physical well-being?': 'Regular exercise<br>Healthy eating', '4. How do you care for your mental well-being?': 'Meditation<br>Reading', '5. What are your activities?': 'Public speaking<br>Writing', '6. What are your resources?': 'Books<br>Community support', '7. Who do you care about?': 'Family<br>Nation', '8. How do you cherish the planet?': 'Promoting sustainability<br>Educating others', '9. What do you need to do more of?': 'Listening to diverse perspectives<br>Engaging in community service', '10. What do you need to do less of?': 'Spending time on trivial matters<br>Neglecting self-care', 'My Intent For the Planet': 'To foster a world of equality and understanding'}\n"
     ]
    }
   ],
   "source": [
    "print(session_example1.responses.responses())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1. What is your world?': 'A place of unity and respect', \"2. What is 'the planet' is for you?\": 'A shared home for all beings', '3. How do you care for your physical well-being?': 'Regular exercise<br>Healthy eating', '4. How do you care for your mental well-being?': 'Meditation<br>Reading', '5. What are your activities?': 'Public speaking<br>Writing', '6. What are your resources?': 'Books<br>Community support', '7. Who do you care about?': 'Family<br>Nation', '8. How do you cherish the planet?': 'Promoting sustainability<br>Educating others', '9. What do you need to do more of?': 'Listening to diverse perspectives<br>Engaging in community service', '10. What do you need to do less of?': 'Spending time on trivial matters<br>Neglecting self-care', 'My Intent For the Planet': 'To foster a world of equality and understanding'}\n"
     ]
    }
   ],
   "source": [
    "print(response_example1.responses())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To foster a world of equality and understanding']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_example1.responses.my_intent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: THIS OVERWRITES ALL ROWS IN SESSIONS.CSV ON GCS!!!! ONLY USE TO INITIALIZE A NEW FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append a Session to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "import streamlit as st\n",
    "\n",
    "\n",
    "def append_to_gcs_file(data_object, gcs_file_name):\n",
    "    data_object_dict = data_object.dict(by_alias=True)\n",
    "    df = pd.json_normalize(data_object_dict, sep='_')\n",
    "\n",
    "    try:\n",
    "        storage_client = storage.Client.from_service_account_info(\n",
    "            st.secrets[\"gcs_connections\"])\n",
    "        bucket = storage_client.get_bucket('streamlit-data-bucket')\n",
    "        blob = bucket.blob('intent/' + gcs_file_name)\n",
    "\n",
    "        # Check if the file exists\n",
    "        if blob.exists():\n",
    "            blob_data = blob.download_as_text()\n",
    "            existing_df = pd.read_csv(io.StringIO(blob_data))\n",
    "            updated_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "        else:\n",
    "            updated_df = df\n",
    "\n",
    "        updated_csv = updated_df.to_csv(index=False)\n",
    "        blob.upload_from_string(updated_csv, content_type='text/csv')\n",
    "    except Exception as e:\n",
    "        st.error(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "append_to_gcs_file(session_example3, 'sessions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output as JSON structured dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(json.dumps(Responses.model_json_schema(), indent=4))\n",
    "print(json.dumps(Session.model_json_schema(), indent=4))\n",
    "# print(json.dumps(IntentStatement.model_json_schema(), indent=4))\n",
    "# print(json.dumps(Individual.model_json_schema(), indent=4))\n",
    "# print(json.dumps(Team.model_json_schema(), indent=4))\n",
    "# print(json.dumps(Organization.model_json_schema(), indent=4))\n",
    "# print(json.dumps(IntentsCollection.model_json_schema(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Qdrant collection. One time only or to recreate it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "import os\n",
    "\n",
    "qdrant_api_key = st.secrets[\"QDRANT_API_KEY_2\"]\n",
    "qdrant_url = st.secrets[\"QDRANT_URL_2\"]\n",
    "\n",
    "client = QdrantClient(\n",
    "    prefer_grpc=True,\n",
    "    url=qdrant_url,\n",
    "    api_key=qdrant_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.recreate_collection(\n",
    "    collection_name=\"iftp\",\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=1536, distance=models.Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into the collection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This apporoach dumps all the responses into two vectors. One contains all the responses and the other contains just the intent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.recreate_collection(\n",
    "    collection_name=\"iftp\",\n",
    "    vectors_config={\"aggregated_responses\": rest.VectorParams(\n",
    "        size=1536, distance=models.Distance.COSINE), \"my_intent\": rest.VectorParams(\n",
    "        size=1536, distance=models.Distance.COSINE)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_data_to_qdrant(session_obj, client):\n",
    "    # Convert the session object to a dictionary using model_dump\n",
    "    session_dict = session_obj.model_dump()\n",
    "\n",
    "    session_id = str(session_dict[\"id\"])\n",
    "    my_intent = str(session_example.responses.my_intent)\n",
    "\n",
    "    # Aggregate all embeddings\n",
    "    all_response_embeddings = []\n",
    "    for responses in session_dict[\"responses\"].values():\n",
    "        for response_text in responses:\n",
    "            embedding = create_embedding(response_text)\n",
    "            all_response_embeddings.append(embedding)\n",
    "\n",
    "    # Average the embeddings if there are any, else use a placeholder (like zeros)\n",
    "    if all_response_embeddings:\n",
    "        aggregated_embedding = np.mean(\n",
    "            all_response_embeddings, axis=0).tolist()\n",
    "    else:\n",
    "        aggregated_embedding = [0] * 1536  # Replace with the correct dimension\n",
    "\n",
    "    # Ensure this returns a list of floats\n",
    "    my_intent_embedding = create_embedding(my_intent)\n",
    "\n",
    "    # Prepare the payload with session details, including the UUID\n",
    "    payload = {\n",
    "        \"session_id\": str(session_dict[\"id\"]),  # UUID as a string\n",
    "        \"facilitator\": session_dict[\"facilitator\"],\n",
    "        \"language\": session_dict[\"language\"],\n",
    "        \"intent\": session_dict[\"responses\"],\n",
    "\n",
    "        # Include other session details as needed\n",
    "    }\n",
    "\n",
    "    # Upsert data into Qdrant\n",
    "    client.upsert(\n",
    "        collection_name=\"iftp\",\n",
    "        points=[\n",
    "            rest.PointStruct(\n",
    "                id=session_id,\n",
    "                vector={\"aggregated_responses\": aggregated_embedding,\n",
    "                        \"my_intent\": my_intent_embedding},\n",
    "\n",
    "                payload=payload,\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "upsert_data_to_qdrant(session_example, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "content = (client.get_collections())\n",
    "\n",
    "all_records = client.scroll(\n",
    "    collection_name=\"iftp\",\n",
    "    limit=100000,\n",
    "    with_payload=True,  # change to True to see the payload\n",
    "    with_vectors=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.count(collection_name=\"iftp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "def query_qdrant(query, vector_name=\"my_intent\", top_k=20):\n",
    "\n",
    "    embedded_query = create_embedding(query)\n",
    "\n",
    "    query_results = client.search(\n",
    "        collection_name=\"iftp\",\n",
    "        query_vector=(\n",
    "            vector_name, embedded_query\n",
    "        ),\n",
    "        limit=top_k,\n",
    "    )\n",
    "\n",
    "    return query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results = query_qdrant(\"what itnents talk about the world?\")\n",
    "for i, my_intent in enumerate(query_results):\n",
    "    print(my_intent.payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
